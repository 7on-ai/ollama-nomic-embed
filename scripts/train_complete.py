#!/usr/bin/env python3
"""
üåç Multilingual Ethical Growth Gating Service - IMPROVED THAI SUPPORT
‚úÖ Uses Ollama LLM with better multilingual prompts
‚úÖ Enhanced Thai language classification
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional
import re
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
import json
import httpx
import logging
import os

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Ethical Growth Gating Service")

# ============================================================
# OLLAMA CONFIGURATION
# ============================================================

OLLAMA_URL = os.getenv("OLLAMA_EXTERNAL_URL", "http://ollama.ollama.svc.cluster.local:11434")
EMBEDDING_MODEL = "nomic-embed-text"  # 768 dimensions
LLM_MODEL = "tinyllama"  # For classification

# ============================================================
# IMPROVED MULTILINGUAL CLASSIFICATION
# ============================================================

async def classify_with_llm(text: str, lang: str) -> Dict:
    """Use Ollama LLM to classify memory with UNIVERSAL multilingual support"""
    
    # ‚úÖ UNIVERSAL: Single multilingual prompt that works for ALL languages
    prompt = f"""You are an ethical growth analyst. You understand ALL languages including English, Thai, Chinese, Japanese, Korean, Spanish, French, German, Arabic, Hindi, and more.

Analyze this text in its original language and respond ONLY with valid JSON.

Text: "{text}"
Language detected: {lang.upper()}

Classify into ONE category. Consider cultural context and language-specific expressions:

Categories (universal across all languages):
- growth_memory: Positive emotions, gratitude, spiritual/religious growth, faith, love, learning, appreciation, thankfulness, worship, devotion, nature appreciation, kindness
- challenge_memory: Negative emotions, aggression, violence, anger, conflict, harm, hatred, destruction, revenge, hostility
- wisdom_moment: Deep philosophical reflection, insights, enlightenment, meditation, contemplation, self-discovery, transcendence
- needs_support: Crisis, despair, self-harm thoughts, severe distress, hopelessness, suicidal ideation
- neutral_interaction: Everyday conversation, neutral statements, factual information, casual chat

Important notes:
- Religious/spiritual content (God, Buddha, Allah, prayer, worship, meditation) = growth_memory or wisdom_moment
- Nature appreciation (trees, sea, mountains, beauty) = growth_memory
- Expressions of love/gratitude = growth_memory
- Violence/harm words = challenge_memory
- Philosophical reflections = wisdom_moment

Provide ethical scores (0.0-1.0) for each dimension based on the content's intent and emotion.

Respond with ONLY this JSON (no markdown, no explanatory text):
{{
  "classification": "category_name",
  "self_awareness": 0.0-1.0,
  "emotional_regulation": 0.0-1.0,
  "compassion": 0.0-1.0,
  "integrity": 0.0-1.0,
  "growth_mindset": 0.0-1.0,
  "wisdom": 0.0-1.0,
  "transcendence": 0.0-1.0,
  "reasoning": "brief explanation in English"
}}"""
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": LLM_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "top_p": 0.9,
                    }
                }
            )
            
            if response.status_code != 200:
                logger.error(f"LLM classification error: {response.status_code}")
                return get_fallback_classification(text, lang)
            
            data = response.json()
            llm_response = data.get("response", "")
            
            # Extract JSON from response
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', llm_response)
            if json_match:
                result = json.loads(json_match.group())
                
                # Validate classification
                valid_classifications = [
                    'growth_memory', 'challenge_memory', 'wisdom_moment', 
                    'needs_support', 'neutral_interaction'
                ]
                
                if result.get('classification') not in valid_classifications:
                    result['classification'] = 'neutral_interaction'
                
                # Ensure all scores are present and valid
                for key in ['self_awareness', 'emotional_regulation', 'compassion', 
                           'integrity', 'growth_mindset', 'wisdom', 'transcendence']:
                    if key not in result or not isinstance(result[key], (int, float)):
                        result[key] = 0.5
                    result[key] = max(0.0, min(1.0, float(result[key])))
                
                logger.info(f"‚úÖ LLM classified as: {result['classification']}")
                return result
            else:
                logger.warning("‚ö†Ô∏è Could not parse LLM JSON response")
                return get_fallback_classification(text, lang)
                
    except Exception as e:
        logger.error(f"‚ùå LLM classification error: {e}")
        return get_fallback_classification(text, lang)

def get_fallback_classification(text: str, lang: str) -> Dict:
    """UNIVERSAL fallback with multilingual keyword detection"""
    text_lower = text.lower()
    
    # ‚úÖ MULTILINGUAL: Universal keywords across languages
    
    # Growth/Positive keywords (multilingual)
    growth_keywords = {
        'en': ['love', 'thank', 'grateful', 'learn', 'improve', 'grow', 'appreciate', 'god', 'buddha', 'jesus', 'allah', 'prayer', 'worship', 'nature', 'beautiful', 'tree', 'mountain', 'sea', 'kind', 'help', 'compassion'],
        'th': ['‡∏£‡∏±‡∏Å', '‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì', '‡∏Å‡∏ï‡∏±‡∏ç‡∏ç‡∏π', '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï', '‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤', '‡∏û‡∏£‡∏∞', '‡∏ò‡∏£‡∏£‡∏°', '‡∏ö‡∏π‡∏ä‡∏≤', '‡∏™‡∏ß‡∏î‡∏°‡∏ô‡∏ï‡πå', '‡∏ó‡∏≥‡∏ö‡∏∏‡∏ç', '‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥', '‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ', '‡∏†‡∏π‡πÄ‡∏Ç‡∏≤', '‡∏ó‡∏∞‡πÄ‡∏•', '‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°', '‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á', '‡∏î‡∏µ‡∏á‡∏≤‡∏°', '‡πÉ‡∏à‡∏î‡∏µ', '‡πÄ‡∏°‡∏ï‡∏ï‡∏≤', '‡∏Å‡∏£‡∏∏‡∏ì‡∏≤'],
        'zh': ['Áà±', 'ÊÑüË∞¢', 'ÊÑüÊÅ©', 'Â≠¶‰π†', 'ÊàêÈïø', 'ËøõÊ≠•', '‰Ωõ', '‰∏äÂ∏ù', 'Á•∑Âëä', 'ÂÜ•ÊÉ≥', 'Ëá™ÁÑ∂', 'Áæé‰∏Ω', 'Ê†ë', 'Â±±', 'Êµ∑', 'ÂñÑËâØ', 'Â∏ÆÂä©', 'ÊÖàÊÇ≤'],
        'ja': ['ÊÑõ', 'ÊÑüË¨ù', 'Â≠¶„Å∂', 'ÊàêÈï∑', '‰ªè', 'Á•û', 'Á•à„Çä', 'ÁûëÊÉ≥', 'Ëá™ÁÑ∂', 'Áæé„Åó„ÅÑ', 'Êú®', 'Â±±', 'Êµ∑', 'ÂÑ™„Åó„ÅÑ', 'Âä©„Åë„Çã', 'ÊÖàÊÇ≤'],
        'ko': ['ÏÇ¨Îûë', 'Í∞êÏÇ¨', 'Î∞∞Ïö∞Îã§', 'ÏÑ±Ïû•', 'Î∂ÄÏ≤ò', 'ÌïòÎÇòÎãò', 'Í∏∞ÎèÑ', 'Î™ÖÏÉÅ', 'ÏûêÏó∞', 'ÏïÑÎ¶ÑÎã§Ïö¥', 'ÎÇòÎ¨¥', 'ÏÇ∞', 'Î∞îÎã§', 'ÏπúÏ†à', 'ÎèïÎã§', 'ÏûêÎπÑ'],
        'es': ['amor', 'gracias', 'agradecer', 'aprender', 'crecer', 'mejorar', 'dios', 'jes√∫s', 'oraci√≥n', 'rezar', 'naturaleza', 'hermoso', '√°rbol', 'monta√±a', 'mar', 'amable', 'ayudar', 'compasi√≥n'],
        'fr': ['amour', 'merci', 'reconnaissant', 'apprendre', 'grandir', 'am√©liorer', 'dieu', 'j√©sus', 'pri√®re', 'prier', 'nature', 'beau', 'arbre', 'montagne', 'mer', 'gentil', 'aider', 'compassion'],
        'de': ['liebe', 'danke', 'dankbar', 'lernen', 'wachsen', 'verbessern', 'gott', 'jesus', 'gebet', 'beten', 'natur', 'sch√∂n', 'baum', 'berg', 'meer', 'freundlich', 'helfen', 'mitgef√ºhl'],
        'ar': ['ÿ≠ÿ®', 'ÿ¥ŸÉÿ±', 'ŸÖŸÖÿ™ŸÜ', 'ÿ™ÿπŸÑŸÖ', 'ŸÜŸÖŸà', 'ÿ™ÿ≠ÿ≥ŸÜ', 'ÿßŸÑŸÑŸá', 'ÿµŸÑÿßÿ©', 'ÿØÿπÿßÿ°', 'ÿ∑ÿ®Ÿäÿπÿ©', 'ÿ¨ŸÖŸäŸÑ', 'ÿ¥ÿ¨ÿ±ÿ©', 'ÿ¨ÿ®ŸÑ', 'ÿ®ÿ≠ÿ±', 'ŸÑÿ∑ŸäŸÅ', 'ŸÖÿ≥ÿßÿπÿØÿ©', 'ÿ±ÿ≠ŸÖÿ©'],
        'hi': ['‡§™‡•ç‡§Ø‡§æ‡§∞', '‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§Ü‡§≠‡§æ‡§∞‡•Ä', '‡§∏‡•Ä‡§ñ‡§®‡§æ', '‡§¨‡§¢‡§º‡§®‡§æ', '‡§∏‡•Å‡§ß‡§æ‡§∞', '‡§≠‡§ó‡§µ‡§æ‡§®', '‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡§æ', '‡§™‡•Ç‡§ú‡§æ', '‡§™‡•ç‡§∞‡§ï‡•É‡§§‡§ø', '‡§∏‡•Å‡§Ç‡§¶‡§∞', '‡§™‡•á‡§°‡§º', '‡§™‡§π‡§æ‡§°‡§º', '‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞', '‡§¶‡§Ø‡§æ‡§≤‡•Å', '‡§Æ‡§¶‡§¶', '‡§ï‡§∞‡•Å‡§£‡§æ'],
        'pt': ['amor', 'obrigado', 'grato', 'aprender', 'crescer', 'melhorar', 'deus', 'jesus', 'ora√ß√£o', 'rezar', 'natureza', 'bonito', '√°rvore', 'montanha', 'mar', 'gentil', 'ajudar', 'compaix√£o'],
        'ru': ['–ª—é–±–æ–≤—å', '—Å–ø–∞—Å–∏–±–æ', '–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', '—É—á–∏—Ç—å—Å—è', '—Ä–∞—Å—Ç–∏', '—É–ª—É—á—à–∞—Ç—å', '–±–æ–≥', '–∏–∏—Å—É—Å', '–º–æ–ª–∏—Ç–≤–∞', '–º–æ–ª–∏—Ç—å—Å—è', '–ø—Ä–∏—Ä–æ–¥–∞', '–∫—Ä–∞—Å–∏–≤—ã–π', '–¥–µ—Ä–µ–≤–æ', '–≥–æ—Ä–∞', '–º–æ—Ä–µ', '–¥–æ–±—Ä—ã–π', '–ø–æ–º–æ–≥–∞—Ç—å', '—Å–æ—Å—Ç—Ä–∞–¥–∞–Ω–∏–µ'],
        'it': ['amore', 'grazie', 'grato', 'imparare', 'crescere', 'migliorare', 'dio', 'ges√π', 'preghiera', 'pregare', 'natura', 'bello', 'albero', 'montagna', 'mare', 'gentile', 'aiutare', 'compassione'],
    }
    
    # Challenge/Negative keywords (multilingual)
    challenge_keywords = {
        'en': ['kill', 'murder', 'hurt', 'harm', 'attack', 'hate', 'destroy', 'revenge', 'violent', 'angry', 'rage', 'fight'],
        'th': ['‡∏Ü‡πà‡∏≤', '‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢', '‡πÇ‡∏Å‡∏£‡∏ò', '‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î', '‡∏ó‡∏≥‡∏•‡∏≤‡∏¢', '‡∏£‡πâ‡∏≤‡∏¢', '‡πÅ‡∏Å‡πâ‡πÅ‡∏Ñ‡πâ‡∏ô', '‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡∏ï‡πà‡∏≠‡∏™‡∏π‡πâ', '‡πÇ‡∏Å‡∏á', '‡∏´‡∏•‡∏≠‡∏Å‡∏•‡∏ß‡∏á'],
        'zh': ['ÊùÄ', 'Ë∞ãÊùÄ', '‰º§ÂÆ≥', 'ÊîªÂáª', 'ÊÅ®', 'ÊØÅÁÅ≠', 'Êä•Â§ç', 'Êö¥Âäõ', 'ÊÑ§ÊÄí', 'ÊâìÊû∂'],
        'ja': ['ÊÆ∫„Åô', 'ÊÆ∫‰∫∫', 'ÂÇ∑„Å§„Åë„Çã', 'ÊîªÊíÉ', 'ÊÜé„ÇÄ', 'Á†¥Â£ä', 'Âæ©ËÆê', 'Êö¥Âäõ', 'ÊÄí„Çä', 'Êà¶„ÅÜ'],
        'ko': ['Ï£ΩÏù¥Îã§', 'ÏÇ¥Ïù∏', 'Ìï¥ÏπòÎã§', 'Í≥µÍ≤©', 'ÎØ∏ÏõåÌïòÎã§', 'ÌååÍ¥¥', 'Î≥µÏàò', 'Ìè≠Î†•', 'Î∂ÑÎÖ∏', 'Ïã∏Ïö∞Îã§'],
        'es': ['matar', 'asesinar', 'herir', 'da√±ar', 'atacar', 'odiar', 'destruir', 'venganza', 'violento', 'enojado'],
        'fr': ['tuer', 'assassiner', 'blesser', 'nuire', 'attaquer', 'ha√Ør', 'd√©truire', 'vengeance', 'violent', 'en col√®re'],
        'de': ['t√∂ten', 'morden', 'verletzen', 'schaden', 'angreifen', 'hassen', 'zerst√∂ren', 'rache', 'gewaltt√§tig', 'w√ºtend'],
        'ar': ['ŸÇÿ™ŸÑ', 'ÿ¨ÿ±ŸäŸÖÿ©', 'ÿ•Ÿäÿ∞ÿßÿ°', 'ÿ∂ÿ±ÿ±', 'Ÿáÿ¨ŸàŸÖ', 'ŸÉÿ±ÿßŸáŸäÿ©', 'ÿ™ÿØŸÖŸäÿ±', 'ÿßŸÜÿ™ŸÇÿßŸÖ', 'ÿπŸÜŸÅ', 'ÿ∫ÿ∂ÿ®'],
        'hi': ['‡§Æ‡§æ‡§∞‡§®‡§æ', '‡§π‡§§‡•ç‡§Ø‡§æ', '‡§ö‡•ã‡§ü', '‡§®‡•Å‡§ï‡§∏‡§æ‡§®', '‡§π‡§Æ‡§≤‡§æ', '‡§®‡§´‡§∞‡§§', '‡§®‡§∑‡•ç‡§ü', '‡§¨‡§¶‡§≤‡§æ', '‡§π‡§ø‡§Ç‡§∏‡§ï', '‡§ó‡•Å‡§∏‡•ç‡§∏‡§æ'],
        'pt': ['matar', 'assassinar', 'ferir', 'prejudicar', 'atacar', 'odiar', 'destruir', 'vingan√ßa', 'violento', 'irritado'],
        'ru': ['—É–±–∏—Ç—å', '—É–±–∏–π—Å—Ç–≤–æ', '—Ä–∞–Ω–∏—Ç—å', '–≤—Ä–µ–¥', '–∞—Ç–∞–∫–∞', '–Ω–µ–Ω–∞–≤–∏–¥–µ—Ç—å', '—É–Ω–∏—á—Ç–æ–∂–∏—Ç—å', '–º–µ—Å—Ç—å', '–Ω–∞—Å–∏–ª–∏–µ', '–∑–ª–æ–π'],
        'it': ['uccidere', 'assassinare', 'ferire', 'danneggiare', 'attaccare', 'odiare', 'distruggere', 'vendetta', 'violento', 'arrabbiato'],
    }
    
    # Wisdom keywords (multilingual)
    wisdom_keywords = {
        'en': ['wisdom', 'insight', 'enlightenment', 'meditation', 'contemplation', 'reflection', 'philosophy', 'truth', 'understanding', 'awareness'],
        'th': ['‡∏õ‡∏±‡∏ç‡∏ç‡∏≤', '‡∏™‡∏ï‡∏¥', '‡∏™‡∏°‡∏≤‡∏ò‡∏¥', '‡∏ï‡∏£‡∏±‡∏™‡∏£‡∏π‡πâ', '‡πÑ‡∏ï‡∏£‡πà‡∏ï‡∏£‡∏≠‡∏á', '‡∏õ‡∏£‡∏±‡∏ä‡∏ç‡∏≤', '‡∏ò‡∏£‡∏£‡∏°‡∏∞', '‡∏ß‡∏¥‡∏õ‡∏±‡∏™‡∏™‡∏ô‡∏≤', '‡∏£‡∏π‡πâ‡πÅ‡∏à‡πâ‡∏á'],
        'zh': ['Êô∫ÊÖß', 'Ê¥ûÂØü', 'ËßâÊÇü', 'ÂÜ•ÊÉ≥', 'Ê≤âÊÄù', 'ÂèçÊÄù', 'Âì≤Â≠¶', 'ÁúüÁêÜ', 'ÁêÜËß£', 'ÊÑèËØÜ'],
        'ja': ['Áü•ÊÅµ', 'Ê¥ûÂØü', 'ÊÇü„Çä', 'ÁûëÊÉ≥', 'ÁÜüËÄÉ', 'ÂèçÁúÅ', 'Âì≤Â≠¶', 'ÁúüÁêÜ', 'ÁêÜËß£', 'ÊÑèË≠ò'],
        'ko': ['ÏßÄÌòú', 'ÌÜµÏ∞∞', 'Íπ®Îã¨Ïùå', 'Î™ÖÏÉÅ', 'ÏàôÍ≥†', 'Î∞òÏÑ±', 'Ï≤†Ìïô', 'ÏßÑÎ¶¨', 'Ïù¥Ìï¥', 'Ïù∏Ïãù'],
        'es': ['sabidur√≠a', 'perspicacia', 'iluminaci√≥n', 'meditaci√≥n', 'contemplaci√≥n', 'reflexi√≥n', 'filosof√≠a', 'verdad', 'comprensi√≥n'],
        'fr': ['sagesse', 'perspicacit√©', 'illumination', 'm√©ditation', 'contemplation', 'r√©flexion', 'philosophie', 'v√©rit√©', 'compr√©hension'],
        'de': ['weisheit', 'einsicht', 'erleuchtung', 'meditation', 'kontemplation', 'reflexion', 'philosophie', 'wahrheit', 'verst√§ndnis'],
        'ar': ['ÿ≠ŸÉŸÖÿ©', 'ÿ®ÿµŸäÿ±ÿ©', 'ÿ™ŸÜŸàŸäÿ±', 'ÿ™ÿ£ŸÖŸÑ', 'ÿ™ŸÅŸÉŸäÿ±', 'ŸÅŸÑÿ≥ŸÅÿ©', 'ÿ≠ŸÇŸäŸÇÿ©', 'ŸÅŸáŸÖ', 'ŸàÿπŸä'],
        'hi': ['‡§ú‡•ç‡§û‡§æ‡§®', '‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø', '‡§ú‡•ç‡§û‡§æ‡§®‡•ã‡§¶‡§Ø', '‡§ß‡•ç‡§Ø‡§æ‡§®', '‡§ö‡§ø‡§Ç‡§§‡§®', '‡§¶‡§∞‡•ç‡§∂‡§®', '‡§∏‡§§‡•ç‡§Ø', '‡§∏‡§Æ‡§ù', '‡§ú‡§æ‡§ó‡§∞‡•Ç‡§ï‡§§‡§æ'],
        'pt': ['sabedoria', 'percep√ß√£o', 'ilumina√ß√£o', 'medita√ß√£o', 'contempla√ß√£o', 'reflex√£o', 'filosofia', 'verdade', 'compreens√£o'],
        'ru': ['–º—É–¥—Ä–æ—Å—Ç—å', '–ø—Ä–æ–∑—Ä–µ–Ω–∏–µ', '–ø—Ä–æ—Å–≤–µ—Ç–ª–µ–Ω–∏–µ', '–º–µ–¥–∏—Ç–∞—Ü–∏—è', '—Å–æ–∑–µ—Ä—Ü–∞–Ω–∏–µ', '—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ', '—Ñ–∏–ª–æ—Å–æ—Ñ–∏—è', '–∏—Å—Ç–∏–Ω–∞', '–ø–æ–Ω–∏–º–∞–Ω–∏–µ'],
        'it': ['saggezza', 'intuizione', 'illuminazione', 'meditazione', 'contemplazione', 'riflessione', 'filosofia', 'verit√†', 'comprensione'],
    }
    
    # Get keywords for detected language (with English as fallback)
    growth_kw = growth_keywords.get(lang, []) + growth_keywords.get('en', [])
    challenge_kw = challenge_keywords.get(lang, []) + challenge_keywords.get('en', [])
    wisdom_kw = wisdom_keywords.get(lang, []) + wisdom_keywords.get('en', [])
    
    # Check growth keywords
    if any(keyword in text for keyword in growth_kw):
        return {
            'classification': 'growth_memory',
            'self_awareness': 0.7,
            'emotional_regulation': 0.6,
            'compassion': 0.7,
            'integrity': 0.6,
            'growth_mindset': 0.7,
            'wisdom': 0.6,
            'transcendence': 0.6,
            'reasoning': f'Fallback: Growth keywords detected in {lang}'
        }
    
    # Check challenge keywords
    if any(keyword in text for keyword in challenge_kw):
        return {
            'classification': 'challenge_memory',
            'self_awareness': 0.3,
            'emotional_regulation': 0.2,
            'compassion': 0.4,
            'integrity': 0.4,
            'growth_mindset': 0.3,
            'wisdom': 0.3,
            'transcendence': 0.2,
            'reasoning': f'Fallback: Challenge keywords detected in {lang}'
        }
    
    # Check wisdom keywords
    if any(keyword in text for keyword in wisdom_kw):
        return {
            'classification': 'wisdom_moment',
            'self_awareness': 0.7,
            'emotional_regulation': 0.7,
            'compassion': 0.7,
            'integrity': 0.7,
            'growth_mindset': 0.7,
            'wisdom': 0.8,
            'transcendence': 0.7,
            'reasoning': f'Fallback: Wisdom keywords detected in {lang}'
        }
    
    # Default neutral
    return {
        'classification': 'neutral_interaction',
        'self_awareness': 0.5,
        'emotional_regulation': 0.5,
        'compassion': 0.5,
        'integrity': 0.5,
        'growth_mindset': 0.5,
        'wisdom': 0.5,
        'transcendence': 0.3,
        'reasoning': f'Fallback: Neutral classification for {lang}'
    }

# ============================================================
# EMBEDDING GENERATION
# ============================================================

async def generate_embedding(text: str) -> Optional[List[float]]:
    """Generate embedding using Ollama nomic-embed-text"""
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{OLLAMA_URL}/api/embeddings",
                json={
                    "model": EMBEDDING_MODEL,
                    "prompt": text
                }
            )
            
            if response.status_code != 200:
                logger.error(f"Ollama error: {response.status_code}")
                return None
            
            data = response.json()
            embedding = data.get("embedding")
            
            if not embedding or len(embedding) != 768:
                logger.error(f"Invalid embedding dimension: {len(embedding) if embedding else 0}")
                return None
            
            return embedding
            
    except Exception as e:
        logger.error(f"Embedding generation error: {e}")
        return None

# ============================================================
# HELPER FUNCTIONS
# ============================================================

def detect_language(text: str) -> str:
    """Enhanced language detection for 15+ languages"""
    # Thai
    if re.search(r'[\u0E00-\u0E7F]', text):
        return 'th'
    # Chinese (Simplified/Traditional)
    elif re.search(r'[\u4E00-\u9FFF]', text):
        return 'zh'
    # Japanese (Hiragana/Katakana/Kanji)
    elif re.search(r'[\u3040-\u309F\u30A0-\u30FF]', text):
        return 'ja'
    # Korean (Hangul)
    elif re.search(r'[\uAC00-\uD7AF]', text):
        return 'ko'
    # Arabic
    elif re.search(r'[\u0600-\u06FF]', text):
        return 'ar'
    # Hebrew
    elif re.search(r'[\u0590-\u05FF]', text):
        return 'he'
    # Hindi/Devanagari
    elif re.search(r'[\u0900-\u097F]', text):
        return 'hi'
    # Cyrillic (Russian, Ukrainian, etc.)
    elif re.search(r'[\u0400-\u04FF]', text):
        return 'ru'
    # Greek
    elif re.search(r'[\u0370-\u03FF]', text):
        return 'el'
    # Latin-based languages - detect by common words/patterns
    else:
        text_lower = text.lower()
        # Spanish
        if any(word in text_lower for word in ['el', 'la', 'los', 'las', 'que', 'de', 'y', 'a', 'en', 'es', 'por', 'para', 'con', 'su', 'este', 'una', 'muy', 'qu√©', 'c√≥mo', 'a√±o', 'espa√±ol']):
            return 'es'
        # French
        elif any(word in text_lower for word in ['le', 'la', 'les', 'de', 'des', 'un', 'une', 'et', 'est', '√†', 'dans', 'pour', 'ce', 'qui', 'avec', '√™tre', 'tr√®s', 'o√π', 'comment', 'fran√ßais']):
            return 'fr'
        # German
        elif any(word in text_lower for word in ['der', 'die', 'das', 'den', 'dem', 'und', 'ist', 'in', 'zu', 'mit', 'von', 'f√ºr', 'auf', 'auch', 'wie', 'wo', 'warum', 'deutsch']):
            return 'de'
        # Portuguese
        elif any(word in text_lower for word in ['o', 'a', 'os', 'as', 'de', 'do', 'da', 'dos', 'das', 'em', 'no', 'na', 'por', 'para', 'com', 'que', '√©', 'um', 'uma', 'n√£o', 'muito', 'como', 'portugu√™s']):
            return 'pt'
        # Italian
        elif any(word in text_lower for word in ['il', 'lo', 'la', 'i', 'gli', 'le', 'di', 'da', 'in', 'con', 'su', 'per', 'tra', 'fra', 'che', '√®', 'un', 'una', 'non', 'molto', 'come', 'italiano']):
            return 'it'
        # Dutch
        elif any(word in text_lower for word in ['de', 'het', 'een', 'van', 'in', 'is', 'en', 'op', 'te', 'voor', 'met', 'dat', 'dit', 'zijn', 'niet', 'zeer', 'hoe', 'waar', 'nederlands']):
            return 'nl'
        # Swedish
        elif any(word in text_lower for word in ['det', 'som', 'en', 'och', '√§r', 'p√•', 'i', 'f√∂r', 'att', 'med', 'av', 'till', 'fr√•n', 'inte', 'mycket', 'hur', 'var', 'svenska']):
            return 'sv'
        # Norwegian
        elif any(word in text_lower for word in ['det', 'som', 'en', 'og', 'er', 'p√•', 'i', 'for', '√•', 'med', 'av', 'til', 'fra', 'ikke', 'veldig', 'hvordan', 'hvor', 'norsk']):
            return 'no'
        # Danish
        elif any(word in text_lower for word in ['det', 'som', 'en', 'og', 'er', 'p√•', 'i', 'for', 'at', 'med', 'af', 'til', 'fra', 'ikke', 'meget', 'hvordan', 'hvor', 'dansk']):
            return 'da'
        # Polish
        elif any(word in text_lower for word in ['to', 'jest', '≈ºe', 'w', 'i', 'na', 'z', 'do', 'o', 'nie', 'siƒô', 'jak', 'bardzo', 'gdzie', 'polski']):
            return 'pl'
        # Turkish
        elif any(word in text_lower for word in ['bu', 've', 'bir', 'i√ßin', 'ile', 'de', 'da', 'ne', '√ßok', 'nasƒ±l', 'nerede', 't√ºrk√ße']):
            return 'tr'
        # Vietnamese
        elif any(word in text_lower for word in ['v√†', 'c·ªßa', 'l√†', 'c√≥', 'trong', 'v·ªõi', 'cho', 'kh√¥ng', 'r·∫•t', 'nh∆∞', 'th·∫ø', 'n√†o', '·ªü', 'ƒë√¢u', 'ti·∫øng', 'vi·ªát']):
            return 'vi'
        # Indonesian/Malay
        elif any(word in text_lower for word in ['yang', 'dan', 'di', 'ke', 'dari', 'dengan', 'untuk', 'ini', 'itu', 'tidak', 'sangat', 'bagaimana', 'dimana', 'bahasa', 'indonesia']):
            return 'id'
        # Default to English
        else:
            return 'en'

def detect_moments(ethical_scores: Dict, classification: str) -> List[Dict]:
    """Detect significant moments based on scores and classification"""
    moments = []
    
    if ethical_scores.get('self_awareness', 0) > 0.7:
        moments.append({
            'type': 'breakthrough',
            'severity': 'positive',
            'description': 'High self-awareness detected',
            'timestamp': datetime.now().isoformat()
        })
    
    if ethical_scores.get('emotional_regulation', 0) < 0.3:
        moments.append({
            'type': 'struggle',
            'severity': 'neutral',
            'description': 'Emotional difficulty detected',
            'timestamp': datetime.now().isoformat()
        })
    
    if classification == 'needs_support':
        moments.append({
            'type': 'crisis',
            'severity': 'critical',
            'description': 'User needs support',
            'timestamp': datetime.now().isoformat(),
            'requires_intervention': True
        })
    
    if classification in ['growth_memory', 'wisdom_moment']:
        moments.append({
            'type': 'growth',
            'severity': 'positive',
            'description': 'Growth or wisdom detected',
            'timestamp': datetime.now().isoformat()
        })
    
    return moments

def determine_growth_stage(ethical_scores: Dict[str, float]) -> int:
    """Determine growth stage from ethical scores"""
    avg_score = sum(ethical_scores.values()) / len(ethical_scores)
    
    if avg_score < 0.3:
        return 1
    elif avg_score < 0.5:
        return 2
    elif avg_score < 0.7:
        return 3
    elif avg_score < 0.85:
        return 4
    else:
        return 5

# ============================================================
# DATABASE OPERATIONS
# ============================================================

def save_ethical_profile(user_id: str, ethical_scores: Dict, stage: int, db_conn):
    cursor = db_conn.cursor()
    
    cursor.execute("""
        INSERT INTO user_data_schema.ethical_profiles 
        (user_id, self_awareness, emotional_regulation, compassion, 
         integrity, growth_mindset, wisdom, transcendence, growth_stage, updated_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
        ON CONFLICT (user_id) 
        DO UPDATE SET
            self_awareness = EXCLUDED.self_awareness,
            emotional_regulation = EXCLUDED.emotional_regulation,
            compassion = EXCLUDED.compassion,
            integrity = EXCLUDED.integrity,
            growth_mindset = EXCLUDED.growth_mindset,
            wisdom = EXCLUDED.wisdom,
            transcendence = EXCLUDED.transcendence,
            growth_stage = EXCLUDED.growth_stage,
            total_interactions = ethical_profiles.total_interactions + 1,
            updated_at = NOW()
    """, (
        user_id,
        ethical_scores['self_awareness'],
        ethical_scores['emotional_regulation'],
        ethical_scores['compassion'],
        ethical_scores['integrity'],
        ethical_scores['growth_mindset'],
        ethical_scores['wisdom'],
        ethical_scores['transcendence'],
        stage
    ))
    
    db_conn.commit()
    cursor.close()

async def save_memory_with_embedding(
    user_id: str, 
    text: str,
    embedding: List[float],
    classification: str,
    lang: str,
    growth_stage: int,
    db_conn
) -> str:
    """Save to memory_embeddings with vector and metadata"""
    cursor = db_conn.cursor()
    
    vector_str = f"[{','.join(map(str, embedding))}]"
    
    metadata = {
        'classification': classification,
        'language': lang,
        'growth_stage': growth_stage,
        'source': 'gating_service',
        'created_at': datetime.now().isoformat()
    }
    
    cursor.execute("""
        INSERT INTO user_data_schema.memory_embeddings
        (user_id, content, embedding, metadata, created_at)
        VALUES (%s, %s, %s::vector, %s, NOW())
        RETURNING id
    """, (
        user_id,
        text,
        vector_str,
        json.dumps(metadata)
    ))
    
    memory_id = cursor.fetchone()[0]
    db_conn.commit()
    cursor.close()
    
    logger.info(f"‚úÖ Memory saved with ID: {memory_id}")
    return str(memory_id)

def save_interaction_memory(
    user_id: str, 
    text: str, 
    classification: str,
    ethical_scores: Dict,
    moments: List[Dict],
    reflection_prompt: str,
    gentle_guidance: Optional[str],
    memory_embedding_id: str,
    db_conn
):
    """Save to interaction_memories with link to memory_embeddings"""
    cursor = db_conn.cursor()
    
    cursor.execute("""
        INSERT INTO user_data_schema.interaction_memories
        (user_id, text, classification, ethical_scores, moments, 
         reflection_prompt, gentle_guidance, metadata, created_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW())
        RETURNING id
    """, (
        user_id,
        text,
        classification,
        json.dumps(ethical_scores),
        json.dumps(moments),
        reflection_prompt,
        gentle_guidance,
        json.dumps({
            'source': 'gating_service',
            'memory_embedding_id': memory_embedding_id
        })
    ))
    
    db_conn.commit()
    cursor.close()
    logger.info(f"‚úÖ Interaction memory saved")

def get_user_ethical_history(user_id: str, db_conn) -> Dict:
    cursor = db_conn.cursor(cursor_factory=RealDictCursor)
    
    cursor.execute("""
        SELECT * FROM user_data_schema.ethical_profiles
        WHERE user_id = %s
    """, (user_id,))
    
    profile = cursor.fetchone()
    cursor.close()
    
    if profile:
        return {
            'baseline_self_awareness': profile['self_awareness'],
            'baseline_regulation': profile['emotional_regulation'],
            'baseline_compassion': profile['compassion'],
            'baseline_integrity': profile['integrity'],
            'baseline_growth': profile['growth_mindset'],
            'baseline_wisdom': profile['wisdom'],
            'baseline_transcendence': profile['transcendence'],
            'current_stage': profile['growth_stage']
        }
    
    return {
        'baseline_self_awareness': 0.3,
        'baseline_regulation': 0.4,
        'baseline_compassion': 0.4,
        'baseline_integrity': 0.5,
        'baseline_growth': 0.4,
        'baseline_wisdom': 0.3,
        'baseline_transcendence': 0.2,
        'current_stage': 2
    }

# ============================================================
# GUIDANCE TEMPLATES
# ============================================================

GUIDANCE_TEMPLATES = {
    'crisis': {
        'en': "I'm concerned about you. Please reach out to a mental health professional.",
        'th': "‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡πà‡∏ß‡∏á‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≤‡∏Å ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≤‡∏¢‡∏î‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï 1323",
    },
    'emotional_dysregulation': {
        'en': "Take a deep breath. These feelings will pass.",
        'th': "‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤‡∏•‡∏∂‡∏Å‡πÜ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏õ",
    },
}

REFLECTION_PROMPTS = {
    1: {
        'en': "What are you feeling right now?",
        'th': "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
    },
    2: {
        'en': "If someone else were in this situation, how would they feel?",
        'th': "‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ô‡∏µ‡πâ ‡πÄ‡∏Ç‡∏≤‡∏à‡∏∞‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏á?",
    },
    3: {
        'en': "What values does this decision reflect?",
        'th': "‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ô‡∏µ‡πâ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£?",
    },
}

def get_guidance(classification: str, ethical_scores: Dict, lang: str) -> Optional[str]:
    if classification == 'needs_support':
        return GUIDANCE_TEMPLATES['crisis'].get(lang, GUIDANCE_TEMPLATES['crisis']['en'])
    
    if ethical_scores.get('emotional_regulation', 0.5) < 0.3:
        return GUIDANCE_TEMPLATES['emotional_dysregulation'].get(lang, GUIDANCE_TEMPLATES['emotional_dysregulation']['en'])
    
    return None

def get_reflection_prompt(stage: int, lang: str) -> str:
    prompts = REFLECTION_PROMPTS.get(stage, REFLECTION_PROMPTS[2])
    return prompts.get(lang, prompts.get('en', ''))

# ============================================================
# API MODELS
# ============================================================

class GatingRequest(BaseModel):
    user_id: str
    text: str
    database_url: str
    session_id: Optional[str] = None
    metadata: Optional[Dict] = {}

class GatingResponse(BaseModel):
    status: str
    routing: str
    ethical_scores: Dict[str, float]
    growth_stage: int
    moments: List[Dict]
    insights: Optional[Dict] = None
    reflection_prompt: Optional[str] = None
    gentle_guidance: Optional[str] = None
    growth_opportunity: Optional[str] = None
    detected_language: Optional[str] = None
    memory_id: Optional[str] = None

# ============================================================
# MAIN ENDPOINT - LLM CLASSIFICATION
# ============================================================

@app.post("/gating/ethical-route", response_model=GatingResponse)
async def ethical_routing(request: GatingRequest):
    """Process text through ethical growth framework with IMPROVED multilingual LLM classification"""
    
    logger.info(f"üìù Processing text for user {request.user_id}: {request.text[:50]}...")
    
    if not request.database_url:
        raise HTTPException(status_code=400, detail="database_url is required")
    
    db_conn = psycopg2.connect(request.database_url)
    
    try:
        # 1. Detect language
        lang = detect_language(request.text)
        logger.info(f"üåç Detected language: {lang}")
        
        # 2. Generate embedding
        logger.info(f"üß† Generating embedding...")
        embedding = await generate_embedding(request.text)
        
        if not embedding:
            logger.warning("‚ö†Ô∏è  Embedding generation failed")
        
        # 3. ‚úÖ IMPROVED LLM CLASSIFICATION
        logger.info(f"ü§ñ Using LLM for classification (language: {lang})...")
        llm_result = await classify_with_llm(request.text, lang)
        
        classification = llm_result['classification']
        ethical_scores = {
            'self_awareness': llm_result['self_awareness'],
            'emotional_regulation': llm_result['emotional_regulation'],
            'compassion': llm_result['compassion'],
            'integrity': llm_result['integrity'],
            'growth_mindset': llm_result['growth_mindset'],
            'wisdom': llm_result['wisdom'],
            'transcendence': llm_result['transcendence'],
        }
        
        logger.info(f"‚úÖ Classification: {classification}")
        logger.info(f"üìä Reasoning: {llm_result.get('reasoning', 'N/A')}")
        
        # 4. Determine growth stage
        growth_stage = determine_growth_stage(ethical_scores)
        
        # 5. Detect moments
        moments = detect_moments(ethical_scores, classification)
        
        # 6. Generate guidance
        reflection_prompt = get_reflection_prompt(growth_stage, lang)
        gentle_guidance = get_guidance(classification, ethical_scores, lang)
        
        # 7. Save to memory_embeddings
        memory_id = None
        if embedding:
            logger.info(f"üíæ Saving to memory_embeddings...")
            memory_id = await save_memory_with_embedding(
                request.user_id,
                request.text,
                embedding,
                classification,
                lang,
                growth_stage,
                db_conn
            )
        else:
            logger.error("‚ùå Cannot save without embedding")
            raise HTTPException(status_code=500, detail="Embedding generation failed")
        
        # 8. Save ethical profile
        save_ethical_profile(request.user_id, ethical_scores, growth_stage, db_conn)
        
        # 9. Save interaction memory
        save_interaction_memory(
            request.user_id,
            request.text,
            classification,
            ethical_scores,
            moments,
            reflection_prompt,
            gentle_guidance,
            memory_id,
            db_conn
        )
        
        logger.info(f"‚úÖ Processing completed: {classification}")
        
        return GatingResponse(
            status='success',
            routing=classification,
            ethical_scores=ethical_scores,
            growth_stage=growth_stage,
            moments=moments,
            insights={
                'strongest_dimension': max(ethical_scores, key=ethical_scores.get),
                'growth_area': min(ethical_scores, key=ethical_scores.get),
                'llm_reasoning': llm_result.get('reasoning', 'N/A')
            },
            reflection_prompt=reflection_prompt,
            gentle_guidance=gentle_guidance,
            growth_opportunity=f"Stage {growth_stage}/5",
            detected_language=lang,
            memory_id=memory_id
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db_conn.close()

@app.get("/health")
async def health():
    """Health check endpoint"""
    return {
        "status": "healthy", 
        "service": "ethical_growth_gating",
        "version": "4.0-universal-multilingual",
        "supported_languages": [
            "English (en)", "Thai (th)", "Chinese (zh)", "Japanese (ja)", 
            "Korean (ko)", "Spanish (es)", "French (fr)", "German (de)", 
            "Portuguese (pt)", "Russian (ru)", "Italian (it)", "Arabic (ar)",
            "Hindi (hi)", "Dutch (nl)", "Swedish (sv)", "Norwegian (no)",
            "Danish (da)", "Polish (pl)", "Turkish (tr)", "Vietnamese (vi)",
            "Indonesian (id)", "Greek (el)", "Hebrew (he)",
            "and more..."
        ],
        "multilingual": True,
        "embedding_model": EMBEDDING_MODEL,
        "classification_model": LLM_MODEL,
        "ollama_url": OLLAMA_URL
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)